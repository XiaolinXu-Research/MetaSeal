{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaSeal Demo\n",
    "\n",
    "This notebook demonstrates an end-to-end MetaSeal flow:\n",
    "1. Generate a caption from an image.\n",
    "2. Sign the caption with ECDSA.\n",
    "3. Encode caption + signature into a QR payload.\n",
    "4. Run MetaSeal inference.\n",
    "5. Decode and verify the recovered signature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running the notebook, make sure the following are available:\n",
    "- Input image at `./data/image/cover_0.png`\n",
    "- Key files: `private_key.pem` and `public_key.pem`\n",
    "- Model/runtime dependencies (Transformers, Torch, Cryptography, qrcode, pyzbar, etc.)\n",
    "- MetaSeal project paths configured as expected under `./scripts/` and output image paths under `./images/`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Image Caption\n",
    "\n",
    "This cell loads the cover image and uses an image-captioning model to produce text that will be signed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tozhou/.conda/envs/watermark/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/home/tozhou/.conda/envs/watermark/lib/python3.12/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a bird is perched on a rock \n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image = Image.open('./data/image/cover_0.png')\n",
    "\n",
    "image_to_text = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\", device=device)\n",
    "image_to_text.model.config.max_new_tokens = 20 \n",
    "output = image_to_text(image)  # Adjust max_length as needed\n",
    "caption = output[0]['generated_text']\n",
    "print(caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Sign Caption with ECDSA\n",
    "\n",
    "This cell loads the PEM keys, signs the generated caption, and prints the signature in hex format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: a bird is perched on a rock \n",
      "Signature: 304502206cd56cfdaefbb3232b512b789ccfc002eaaeecc04807f7dd91923cd9b28363c4022100ba2a61398050de13a797c91f3657613225b5529c52eb97c6f67281bf2003a612\n"
     ]
    }
   ],
   "source": [
    "from cryptography.hazmat.primitives.asymmetric import ec\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.exceptions import InvalidSignature\n",
    "from cryptography.hazmat.primitives.asymmetric import rsa\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "\n",
    "# # Step 1: Generate an ECDSA key pair\n",
    "# private_key = ec.generate_private_key(ec.SECP256R1())  # SECP256R1 curve for a 256-bit signature\n",
    "# public_key = private_key.public_key()\n",
    "\n",
    "# Load the private key\n",
    "with open(\"private_key.pem\", \"rb\") as f:\n",
    "    private_key = serialization.load_pem_private_key(\n",
    "        f.read(),\n",
    "        password=None,\n",
    "    )\n",
    "    \n",
    "with open(\"public_key.pem\", \"rb\") as f:\n",
    "    public_key = serialization.load_pem_public_key(f.read())\n",
    "\n",
    "# Step 2: Sign the caption\n",
    "caption_bytes = caption.encode('utf-8')  # Convert caption to bytes\n",
    "\n",
    "# Sign using ECDSA\n",
    "signature = private_key.sign(\n",
    "    caption_bytes,\n",
    "    ec.ECDSA(hashes.SHA256())\n",
    ")\n",
    "print(\"Caption:\", caption)\n",
    "print(\"Signature:\", signature.hex())  # Signature in hexadecimal format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build JSON Payload\n",
    "\n",
    "The caption and signature are serialized into a compact JSON payload for QR encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"caption\": \"a bird is perched on a rock \", \"signature\": \"304502206cd56cfdaefbb3232b512b789ccfc002eaaeecc04807f7dd91923cd9b28363c4022100ba2a61398050de13a797c91f3657613225b5529c52eb97c6f67281bf2003a612\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Combine into a JSON object\n",
    "combined_data = json.dumps({\"caption\": str(caption), \"signature\": str(signature.hex())})\n",
    "\n",
    "# Print or use combined_data\n",
    "print(combined_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Secret QR Image\n",
    "\n",
    "This cell converts the JSON payload into a QR image and resizes it to `512x512` for embedding or downstream processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=512x512>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qrcode\n",
    "\n",
    "\n",
    "# Convert the signature to a QR code\n",
    "qr = qrcode.QRCode(\n",
    "    version=1,\n",
    "    error_correction=qrcode.constants.ERROR_CORRECT_L,\n",
    "    box_size=10,  # This will be adjusted to achieve the desired size\n",
    "    border=0,\n",
    ")\n",
    "qr.add_data(combined_data)\n",
    "qr.make(fit=True)\n",
    "\n",
    "# Create an image from the QR Code instance\n",
    "img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n",
    "\n",
    "\n",
    "# Resize the image to 512x512 pixels\n",
    "secret = img.resize((512,512))\n",
    "\n",
    "# Save the image\n",
    "secret.show()\n",
    "# secret.save('dataset/secret_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run MetaSeal Inference\n",
    "\n",
    "Run the model pipeline to recover the hidden secret and report quality metrics (PSNR/SSIM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt:  1\n",
      "total:  1\n",
      "success rate:  1.0\n",
      "20.329952578766992 40.20062895761417 0.98083085\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./scripts/')\n",
    "from scripts.test_ori import inference\n",
    "import scripts.config as c\n",
    "from scripts.dataset import get_data_loaders\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# transformations = ['none','noise', 'brightness', 'contrast', 'blur', 'flip']\n",
    "transformations = ['none']\n",
    "for transformation in transformations:\n",
    "    testloader = get_data_loaders(c, 2, c.cropsize_val, \"val\")\n",
    "    psnr_s, psnr_c, ssim_c = inference(testloader, c, transformation)\n",
    "    print(psnr_s, psnr_c, ssim_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Decode and Verify Signature\n",
    "\n",
    "Finally, decode the recovered QR payload, extract caption/signature, and verify authenticity with the public key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Caption: a living room with a fireplace and a table \n",
      "Decoded Signature: 304502205b2072441f8183d044ed5f3c370ffc5fc293bfbefae172ef37bebb0d226b2dea022100b2205729b74069eb66c5bf9e901ae55c14bfdfa397cfcee6b462bdd260281b42\n",
      "Signature is valid.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "qr_image = Image.open(\"./images/secret-rev/secret_rev_0.png\")\n",
    "# qr_image = Image.open(\"/home/tozhou/project/MetaSeal/dataset/secret_1.png\")\n",
    "decoded_objects = decode(qr_image)\n",
    "if decoded_objects:\n",
    "    # decoded_signature_hex = decoded_objects[0].data.decode('utf-8')  # Decode from byte string to hex string\n",
    "    # decoded_signature = bytes.fromhex(decoded_signature_hex)  # Convert back to bytes\n",
    "    # print(\"Decoded Signature:\", decoded_signature.hex())\n",
    "    combined_data = decoded_objects[0].data\n",
    "\n",
    "    # Split the combined data into caption and signature\n",
    "    # decoded_caption_bytes, decoded_signature = combined_data.split(b'\\x00', 1)\n",
    "    # decoded_caption = decoded_caption_bytes.decode('utf-8')\n",
    "    extracted_data = json.loads(combined_data)\n",
    "    decoded_caption = extracted_data[\"caption\"]\n",
    "    decoded_signature = extracted_data[\"signature\"]\n",
    "\n",
    "    print(\"Decoded Caption:\", decoded_caption)\n",
    "    print(\"Decoded Signature:\", decoded_signature)\n",
    "\n",
    "    decoded_caption_bytes = decoded_caption.encode('utf-8')\n",
    "    decoded_signature = bytes.fromhex(decoded_signature)\n",
    "    try:\n",
    "        public_key.verify(\n",
    "            decoded_signature,\n",
    "            decoded_caption_bytes,\n",
    "            ec.ECDSA(hashes.SHA256())\n",
    "        )\n",
    "        print(\"Signature is valid.\")\n",
    "    except InvalidSignature:\n",
    "        print(\"Signature is invalid.\") \n",
    "else:\n",
    "    print(\"No QR code found in the image.\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Result\n",
    "\n",
    "A successful run should print `Signature is valid.` in the final cell.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
